{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"Xception.ipynb","provenance":[],"collapsed_sections":["fapScGXbnHQE","yWy6LNY_HbGs","v8vy5YipfNpZ","nizW6_FnINK1","4AJQ7Cy5IP-P","wHV7tVDM47gt","D2y4heGdnfMZ","4ozZ_t9n0aZ8"],"mount_file_id":"12-3GjH3jP0kI9WwMczQHf-GPXTCC0__W","authorship_tag":"ABX9TyO2wgNONBK4vB7j01ebHbr2"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fapScGXbnHQE"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"6bnkdXP05BKI"},"source":["# Global Settings\n","SEED = 1\n","VERBOSE_LEVEL = 1\n","DIM = 768\n","DIM_RESIZE = 512\n","EPOCHS = 100\n","BATCH_SIZE = 32\n","NUM_CLASSES = 1\n","\n","LR_MAX = 1e-4\n","LR_MIN = 1e-6\n","LR_START = 1e-5\n","FIND_LR = False\n","SAVE_OUTPUT = True\n","USE_TENSORBOARD = False\n","\n","IMAGE_SIZE = [DIM, DIM]\n","IMAGE_RESIZE = [DIM_RESIZE, DIM_RESIZE]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-lMlfnPtJERu"},"source":["%%capture\n","!pip install tensorflow_addons\n","!pip install efficientnet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GbzG-1aCeIOy"},"source":["import os\n","import re\n","import gc\n","import sys\n","import glob\n","import math\n","import json\n","import shutil\n","import random\n","import warnings\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import tensorflow as tf\n","from pathlib import Path\n","from functools import partial\n","import matplotlib.pyplot as plt\n","import efficientnet.keras as efn\n","from IPython.display import Image\n","from datetime import datetime, date\n","from pandas.core.common import flatten\n","from IPython.display import clear_output\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.utils import plot_model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5aCPhHGbz685"},"source":["# cleanup\n","for f in glob.glob(\"/content/*.png\"):\n","    os.remove(f)\n","\n","for f in glob.glob(\"/content/*.hdf5\"):\n","    os.remove(f)\n","\n","for f in glob.glob(\"/content/*.txt\"):\n","    os.remove(f)\n","\n","for f in glob.glob(\"/content/*.h5\"):\n","    os.remove(f)\n","\n","for f in glob.glob(\"/content/*.json\"):\n","    os.remove(f)\n","\n","!rm -rf logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20Mc7911nKMI"},"source":["%%capture\n","!rm -rf /content/melanoma-classification\n","!rm -rf /content/sample_data/\n","\n","# if we do not have the data\n","if not os.path.exists(\"/content/melanoma-classification/README.md\"):\n","    # install kaggle\n","    !pip install kaggle\n","\n","    # get kaggle auth file\n","    path_to_auth_file = \"kaggle.json\"\n","    if not os.path.exists(path_to_auth_file):\n","        path_to_auth_file = '/content/drive/MyDrive/Colab Notebooks/_auth/kaggle.json'\n","\n","    # read the kaggle.json file\n","    with open(path_to_auth_file) as json_file:\n","        data = json.load(json_file)\n","        os.environ['KAGGLE_USERNAME'] = data[\"username\"]\n","        os.environ['KAGGLE_KEY'] = data[\"key\"]\n","\n","    # remove sample data so we have more space\n","    !rm -rf /content/sample_data\n","\n","    # download kaggle dataset\n","    !kaggle datasets download -d saschamet/melanoma-1-12\n","    !unzip /content/melanoma-1-12.zip\n","    !rm /content/melanoma-1-12.zip\n","\n","    ## pull repo\n","    !git clone https://github.com/SaschaMet/melanoma-classification.git\n","\n","    ## update repo\n","    !cd melanoma-classification && git fetch && git pull\n","\n","    ## switch branch and execute function\n","    !cd /content/melanoma-classification && git checkout \"master\" && git fetch && git reset --hard origin/master"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2bjdSK8a3a2e"},"source":["# make sure the repo ist added to the sys path\n","sys.path.insert(0,'/content/melanoma-classification')\n","sys.path.insert(1,'/content/melanoma-classification/src')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zc0lh2qIemgR"},"source":["# Tensorflow execution optimizations\n","# Source: https://www.tensorflow.org/guide/mixed_precision & https://www.tensorflow.org/xla\n","tpu = None\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n","except:\n","    pass\n","\n","if tpu:\n","    print(\"Try connecting to a tpu\")\n","    try:\n","        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n","        # tf.config.experimental_connect_to_cluster(tpu)\n","        # tf.tpu.experimental.initialize_tpu_system(tpu)\n","        strategy = tf.distribute.TPUStrategy(tpu)\n","        REPLICAS = strategy.num_replicas_in_sync\n","        print(\"REPLICAS:\", REPLICAS)\n","    except ValueError as error:\n","        raise BaseException('An exception occurred: {}'.format(error))\n","    except BaseException as error:\n","        raise BaseException('An exception occurred: {}'.format(error))\n","else:\n","    num_gpus = len(\n","        tf.config.experimental.list_physical_devices('GPU')\n","    )\n","    print(\"Using default strategy for CPU and single GPU\")\n","    print(\"Num GPUs Available: \", num_gpus)\n","    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n","    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n","    mixed_precision.set_policy(policy)\n","    print('Mixed precision enabled')\n","    tf.config.optimizer.set_jit(True)\n","    print('Accelerated Linear Algebra enabled')\n","    strategy = tf.distribute.get_strategy()\n","    REPLICAS = strategy.num_replicas_in_sync\n","    print(\"REPLICAS:\", REPLICAS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRqWQ215ehpE"},"source":["if tpu:\n","    BATCH_SIZE = 128  # increase the batch size if we have a tpu\n","    USE_TENSORBOARD = False # Tensorboard does not work with tpu\n","\n","# Set needed env variables based on the global variables\n","os.environ[\"DIM\"] = str(DIM)\n","os.environ[\"BATCH_SIZE\"] = str(BATCH_SIZE)\n","\n","# seed everything\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","\n","# get the current timestamp. This timestamp is used to save the model data with a unique name\n","now = datetime.now()\n","today = date.today()\n","current_time = now.strftime(\"%H:%M:%S\")\n","timestamp = str(today) + \"_\" + str(current_time)\n","\n","# environment settings\n","print(\"Tensorflow version \" + tf.__version__)\n","AUTOTUNE = tf.data.AUTOTUNE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TIXZjjo6faLK"},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","# Custom imports\n","from model.evaluation import evaluate_model\n","from model.model_callbacks import get_model_callbacks\n","from model.LearningRateFinder import LearningRateFinder\n","from data.verify_tf_records import display_batch_of_images\n","from model.clr_callback import cyclic_learning_rate, get_lr_callback, plot_clr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"52MdpGjdnI3Z"},"source":["## prevent colab shutdown \n","%%javascript\n","function ConnectButton(){\n","    console.log(\"Connect pushed\"); \n","    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n","}\n","\n","var connection = setInterval(ConnectButton, 60000);\n","\n","function myStopFunction() {\n","    console.log(\"Remove interal\"); \n","    clearInterval(connection);\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yWy6LNY_HbGs"},"source":["# Data Loading"]},{"cell_type":"code","metadata":{"id":"OwqRKl5dzLXY"},"source":["def count_data_items(filenames):\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n","    return np.sum(n)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYn_bwBrtKKm"},"source":["MALIGNANT_IMAGES = tf.io.gfile.glob('gs://kds-dd07414d960d14a2a8849e3ab696a4cb3299162b439e521ac886f393/*.tfrec')\n","print(\"MALIGNANT TF Records\", len(MALIGNANT_IMAGES))\n","\n","# This files include all malginant images from 2020, 2019, 2018 and 2017 competition as well as data directly from ISIC\n","# Source: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/169139\n","MALIGNANT_IMAGES_V2 = tf.io.gfile.glob('gs://kds-77aee4ba270735bf8687a77209581d50b8710ff6486f134f19b29759/*train*.tfrec')[15:]\n","print(\"MALIGNANT TF Records V2\", len(MALIGNANT_IMAGES_V2))\n","\n","BENIGN_IMAGES = tf.io.gfile.glob('gs://kds-d499b3e548bc098dfea46bcac127fb30d0e465c2713c8457ff05deff/*.tfrec')\n","print(\"BENIGN TF Records\", len(BENIGN_IMAGES))\n","\n","BENIGN_IMAGES_TRAIN = BENIGN_IMAGES[0:160] # use only the first 160 batches for training\n","\n","TEST_FILENAMES = tf.io.gfile.glob(\"gs://kds-3e36e1551f5588596f9fcb50129d35830a155849a24ad4825763d528/*.tfrec\")\n","print(\"TEST TF Records\", len(TEST_FILENAMES))\n","\n","# Create the Training and Validation Dataset\n","print(\" \")\n","\n","## Training \n","TRAINING_FILENAMES = [MALIGNANT_IMAGES[1], MALIGNANT_IMAGES[0]]\n","TRAINING_FILENAMES = TRAINING_FILENAMES + random.sample(MALIGNANT_IMAGES_V2, 20)\n","TRAINING_FILENAMES = TRAINING_FILENAMES + random.sample(BENIGN_IMAGES_TRAIN, len(TRAINING_FILENAMES))\n","np.random.shuffle(TRAINING_FILENAMES)\n","\n","## Validation \n","VALIDATION_FILENAMES = [\n","    MALIGNANT_IMAGES[2],\n","    BENIGN_IMAGES[162]\n","]\n","\n","TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n","VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n","\n","print(\"TRAINING FILES\", len(TRAINING_FILENAMES))\n","print(\"VALODATION FILES\", len(VALIDATION_FILENAMES))\n","print(\" \")\n","\n","print(\"TRAINING_IMAGES\", TRAINING_IMAGES)\n","print(\"VALIDATION_IMAGES\", VALIDATION_IMAGES)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yzG5emfppD6f"},"source":["AUGMENTATION_CONFIG = dict(\n","    # DATA AUGMENTATION\n","    rot = 180.0,\n","    shr = 1.5,\n","    hzoom = 6.0,\n","    wzoom = 6.0,\n","    hshift = 6.0,\n","    wshift = 6.0,\n","    \n","    # COARSE DROPOUT\n","    DROP_FREQ = 0, # Determines proportion of train images to apply coarse dropout to / Between 0 and 1.\n","    DROP_CT = 0, # How many squares to remove from train images when applying dropout.\n","    DROP_SIZE = 0, # The size of square side equals IMG_SIZE * DROP_SIZE / Between 0 and 1.  \n",")\n","\n","def color(x):\n","    \"\"\"Color augmentation\n","    Args:\n","        x: Image\n","\n","    Returns:\n","        Augmented image\n","    \"\"\"\n","    x = tf.image.random_saturation(x, 0.7, 1.7, seed=SEED)\n","    x = tf.image.random_brightness(x, 0.3, seed=SEED)\n","    x = tf.image.random_contrast(x, 0.5, 1.5, seed=SEED)\n","    return x\n","\n","def flip(x):\n","    \"\"\"Flip augmentation\n","    Args:\n","        x: Image to flip\n","\n","    Returns:\n","        Augmented image\n","    \"\"\"\n","    x = tf.image.random_flip_left_right(x, seed=SEED)\n","    x = tf.image.random_flip_up_down(x, seed=SEED)\n","    return x\n","\n","def rotate(x):\n","    \"\"\"Rotation augmentation\n","    Args:\n","        x: Image\n","\n","    Returns:\n","        Augmented image\n","    \"\"\"\n","    return tf.image.rot90(x, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n","\n","\n","def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n","    # returns 3x3 transformmatrix which transforms indicies\n","        \n","    # CONVERT DEGREES TO RADIANS\n","    rotation = math.pi * rotation / 180.\n","    shear = math.pi * shear / 180.\n","\n","    def get_3x3_mat(lst):\n","        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n","    \n","    # ROTATION MATRIX\n","    c1   = tf.math.cos(rotation)\n","    s1   = tf.math.sin(rotation)\n","    one  = tf.constant([1],dtype='float32')\n","    zero = tf.constant([0],dtype='float32')\n","    \n","    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n","                                   -s1,  c1,   zero, \n","                                   zero, zero, one])    \n","    # SHEAR MATRIX\n","    c2 = tf.math.cos(shear)\n","    s2 = tf.math.sin(shear)    \n","    \n","    shear_matrix = get_3x3_mat([one,  s2,   zero, \n","                                zero, c2,   zero, \n","                                zero, zero, one])        \n","    # ZOOM MATRIX\n","    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n","                               zero,            one/width_zoom, zero, \n","                               zero,            zero,           one])    \n","    # SHIFT MATRIX\n","    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n","                                zero, one,  width_shift, \n","                                zero, zero, one])\n","    \n","    return K.dot(K.dot(rotation_matrix, shear_matrix), \n","                 K.dot(zoom_matrix,     shift_matrix))\n","    \n","\n","def transform(image, cfg=AUGMENTATION_CONFIG):    \n","    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n","    # output - image randomly rotated, sheared, zoomed, and shifted\n","    DIM = DIM_RESIZE\n","    XDIM = DIM%2 #fix for size 331\n","    \n","    rot = cfg['rot'] * tf.random.normal([1], dtype='float32')\n","    shr = cfg['shr'] * tf.random.normal([1], dtype='float32') \n","    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['hzoom']\n","    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['wzoom']\n","    h_shift = cfg['hshift'] * tf.random.normal([1], dtype='float32') \n","    w_shift = cfg['wshift'] * tf.random.normal([1], dtype='float32') \n","\n","    # GET TRANSFORMATION MATRIX\n","    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift)\n","\n","    # LIST DESTINATION PIXEL INDICES\n","    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n","    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n","    z   = tf.ones([DIM*DIM], dtype='int32')\n","    idx = tf.stack( [x,y,z] )\n","    \n","    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n","    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n","    idx2 = K.cast(idx2, dtype='int32')\n","    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n","    \n","    # FIND ORIGIN PIXEL VALUES           \n","    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n","    d    = tf.gather_nd(image, tf.transpose(idx3))\n","        \n","    return tf.reshape(d,[DIM_RESIZE, DIM_RESIZE,3])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pRHlqiBhcG3M"},"source":["def augment_image(image, augment=True):  \n","    augmentations = [transform, color, rotate, flip] \n","    if augment:\n","        # Data augmentation\n","        for f in augmentations:\n","            if random.randint(1, 10) >= 5:\n","                image = f(image)         \n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eWeFwjznHacB"},"source":["def decode_image(image):\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.cast(image, tf.float32)\n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-nB-538DwttF"},"source":["resizing_layer = tf.keras.layers.experimental.preprocessing.Resizing(DIM_RESIZE, DIM_RESIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_yOdmitHkn0"},"source":["def read_tfrecord(example, labeled):\n","    tfrecord_format = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"target\": tf.io.FixedLenFeature([], tf.int64)\n","    } if labeled else {\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n","    }\n","    example = tf.io.parse_single_example(example, tfrecord_format)\n","    image = decode_image(example['image'])\n","    if labeled:\n","        label = tf.cast(example['target'], tf.int32)\n","        return image, label\n","    idnum = example['image_name']\n","    return image, idnum"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15uaXc6cHmBc"},"source":["def load_dataset(filenames, labeled=True, ordered=False):\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False # disable order, increase speed\n","    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.cache() # cache ds for performance gains\n","    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n","    dataset = dataset.map(lambda x, y: (resizing_layer(x), y), num_parallel_calls=AUTOTUNE) # resize the images to the same height and width\n","\n","    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfNmwQPmHp37"},"source":["def get_training_dataset(augment):\n","    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n","    if augment:\n","        dataset = dataset.map(lambda x, y: (augment_image(x, augment=augment), y), num_parallel_calls=AUTOTUNE)\n","    dataset = dataset.repeat()\n","    dataset = dataset.shuffle(TRAINING_IMAGES * 2, reshuffle_each_iteration=True)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTOTUNE)\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxpS3oZeHrR6"},"source":["def get_validation_dataset(ordered=False, repeat=False):\n","    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n","    if repeat:\n","        dataset = dataset.repeat()\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTOTUNE)\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Miky1JY2HshZ"},"source":["def get_test_dataset(ordered=False):\n","    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTOTUNE)\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v8vy5YipfNpZ"},"source":["# Data Validation"]},{"cell_type":"code","metadata":{"id":"4D202mUIqm8M"},"source":["example_dataset = get_training_dataset(augment=False)\n","example_dataset = example_dataset.unbatch().batch(15)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GYhhRdsCfQlH"},"source":["example_batch = iter(example_dataset) \n","image_batch, label_batch = next(example_batch)\n","# because Xception needs a special kind op preprocessing, which plt cannot display correctly,\n","# we do some image processing for plt here\n","images = [(x / 255) for x in image_batch]\n","labels = [l.numpy() for l in label_batch]\n","display_batch_of_images((images, labels), unbatched=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CwGkEXuStM6h"},"source":["augmented_images = [augment_image(x, augment=True) for x in images]\n","augmented_images = [np.clip(x, 0, 1) for x in augmented_images]\n","labels = [l.numpy() for l in label_batch]\n","display_batch_of_images((augmented_images, labels), unbatched=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXBMCwmGho72"},"source":["# images are in float32 format with values between 0 and 255\n","for i in range(10):\n","    image = image_batch[i]\n","    print(\"min:\", np.min(image), \" -  max:\", np.max(image))\n","\n","print(image.dtype)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvvr11Rwhq-a"},"source":["# Iterate over n batches to get the class distribution\n","benign_cases = 0\n","malignant_cases = 0\n","\n","for i in range(0, 50):\n","    x,y = next(example_batch)\n","    for label in y.numpy():\n","        if int(label) == 0:\n","            benign_cases = benign_cases + 1\n","        else:\n","            malignant_cases = malignant_cases + 1\n","\n","\n","initial_bias = np.log([malignant_cases/benign_cases])\n","\n","weight_for_0 = (1 / benign_cases)*(TRAINING_IMAGES)/2.0 \n","weight_for_1 = (1 / malignant_cases)*(TRAINING_IMAGES)/2.0\n","\n","class_weight = {0: weight_for_0, 1: weight_for_1}\n","\n","print(\"benign_cases\", benign_cases)\n","print(\"malignant_cases\", malignant_cases)\n","print(\"ratio\", round(malignant_cases / benign_cases, 2))\n","print(\"initial_bias\", initial_bias)\n","\n","print('Weight for class 0: {:.2f}'.format(weight_for_0))\n","print('Weight for class 1: {:.2f}'.format(weight_for_1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D2k8IQh7opcr"},"source":["# Model Creation"]},{"cell_type":"code","metadata":{"id":"5FP669_7t5gl"},"source":["training_dataset = get_training_dataset(augment=True)\n","validation_dataset = get_validation_dataset(repeat=True)\n","\n","steps_per_epoch = 30\n","validation_steps_per_epoch = 5\n","\n","print(\"Epochs\", EPOCHS)\n","print(\"BATCH SIZE\", BATCH_SIZE)\n","\n","print(\"Train images\", count_data_items(TRAINING_FILENAMES))\n","print(\"Validation images\", count_data_items(VALIDATION_FILENAMES))\n","\n","print(\"steps_per_epoch\", steps_per_epoch)\n","print(\"validation_steps_per_epoch\", validation_steps_per_epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sHktKc1cZUcJ"},"source":["def get_model_parameters(lr):\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","    loss = 'binary_crossentropy'\n","    metrics = [\n","        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n","        tf.keras.metrics.AUC(name='auc'),\n","    ]\n","\n","    return loss, metrics, optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1rwDt9DZWcT"},"source":["def compile_model(model):\n","    loss, metrics, optimizer = get_model_parameters(LR_START)\n","    if tpu:\n","        model.compile(\n","            loss=loss,\n","            metrics=metrics,\n","            optimizer=optimizer,\n","            # Reduce python overhead, and maximize the performance of your TPU\n","            # Anything between 2 and `steps_per_epoch` could help here.\n","            steps_per_execution=int(steps_per_epoch / 10),\n","        )\n","    else:\n","        model.compile(\n","            loss=loss,\n","            metrics=metrics,\n","            optimizer=optimizer,\n","        )\n","\n","    return model\n","\n","\n","def reset_model():\n","    model = tf.keras.models.load_model(\"stage_0.h5\")\n","    model.load_weights(\"stage_0.hdf5\")\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4vSk8gG-xXno"},"source":["# Clear the session - this helps when we are creating multiple models\n","K.clear_session()\n","\n","# Creating the model in the strategy scope places the model on the TPU\n","with strategy.scope():\n","\n","    i = tf.keras.layers.Input([DIM_RESIZE, DIM_RESIZE, 3], dtype = tf.float32)\n","    x = tf.keras.applications.xception.preprocess_input(i)\n","    base_model = tf.keras.applications.Xception(\n","        input_shape=(DIM_RESIZE, DIM_RESIZE, 3),\n","        include_top=False,\n","        weights='imagenet'\n","    )\n","    x = base_model(x)\n","    pretrained_model = tf.keras.Model(inputs=[i], outputs=[x], name=\"xception\")\n","\n","    base_model.trainable = False\n","\n","    if initial_bias is not None:\n","        output_bias = tf.keras.initializers.Constant(initial_bias)\n","\n","    model = tf.keras.models.Sequential([\n","        pretrained_model,\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        tf.keras.layers.Dense(8, activation='relu'),\n","        tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid', bias_initializer=output_bias)\n","    ])\n","\n","    model = compile_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-UFBdVdCYTVJ"},"source":["#plot_model(base_model, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MO3opVovUDWb"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nizW6_FnINK1"},"source":["# Initial Model Training"]},{"cell_type":"code","metadata":{"id":"6h8MHcF8iQOW"},"source":["history = model.fit(\n","    training_dataset,\n","    epochs=10,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=validation_dataset,\n","    validation_steps=validation_steps_per_epoch,\n","    class_weight=class_weight,\n","    verbose=VERBOSE_LEVEL\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8eflzr9ibCw"},"source":["# save the initially trained model, so we can restore it later\n","model.save_weights(\"stage_0.hdf5\")\n","model.save(\"stage_0.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4AJQ7Cy5IP-P"},"source":["# Learning Rate Finder"]},{"cell_type":"code","metadata":{"id":"7-HUtFmckzp-"},"source":["if FIND_LR:\n","    K.clear_session()\n","    with strategy.scope():\n","        print(\"Current LR Min\", LR_MIN)\n","        print(\"Current LR Max\", LR_MAX)\n","\n","        model = reset_model()\n","        model.trainable = True\n","        model = compile_model(model)\n","\n","        # train the model for 20 epochs to update its weights\n","        model.fit(\n","            training_dataset,\n","            epochs=20,\n","            steps_per_epoch=steps_per_epoch,\n","            validation_data=validation_dataset,\n","            validation_steps=validation_steps_per_epoch,\n","            class_weight=class_weight,\n","            verbose=2\n","        )\n","\n","        # then search for the learning rates\n","        lrf = LearningRateFinder(model)\n","        lrf.find(\n","            training_dataset, \n","            startLR=1e-10, \n","            endLR=1e-1,\n","            epochs=30,\n","            stepsPerEpoch=steps_per_epoch, \n","            batchSize=BATCH_SIZE,\n","            verbose=1\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"riVo5o-mBjI1"},"source":["if FIND_LR:\n","    lrf.plot_loss()\n","    !rm -rf /content/lr.hdf5\n","    sys.exit(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wHV7tVDM47gt"},"source":["# Fine Tuning"]},{"cell_type":"code","metadata":{"id":"MMFL0WeTqYfq"},"source":["mode='triangular'\n","step_size=3.\n","clr_callback = get_lr_callback(mode, LR_MIN, LR_MAX, step_size)\n","plot_clr(mode, LR_MIN, LR_MAX, step_size, EPOCHS)\n","\n","# callbacks = get_model_callbacks(VERBOSE_LEVEL, SAVE_OUTPUT, timestamp)\n","clr_callback = get_lr_callback(mode, LR_MIN, LR_MAX, step_size)\n","early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n","\n","callbacks = [clr_callback, early_stopping_cb]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhMM_lyMEyHc"},"source":["K.clear_session()\n","with strategy.scope():\n","    if FIND_LR: # reset the model if we searched for learning rates\n","        model = reset_model()\n","    model.trainable = True\n","    model = compile_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2z4JN8xwVCfX"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tyBtl9ZgZ9Sb"},"source":["history = model.fit(\n","    training_dataset,\n","    epochs=EPOCHS,\n","    callbacks=callbacks,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=validation_dataset,\n","    validation_steps=validation_steps_per_epoch,\n","    class_weight=class_weight,\n","    verbose=VERBOSE_LEVEL\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D2y4heGdnfMZ"},"source":["# Model Evaluation"]},{"cell_type":"code","metadata":{"id":"_SbAiWJftAZk"},"source":["example_validation_dataset = get_validation_dataset()\n","predictions, labels, threshold = evaluate_model(\n","    model=model, \n","    dataset=example_validation_dataset, \n","    history=history,\n","    save_output=SAVE_OUTPUT, \n","    timestamp=timestamp\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ozZ_t9n0aZ8"},"source":["# GH & Submission"]},{"cell_type":"code","metadata":{"id":"tBgadqcD0Z4O"},"source":["%%capture\n","import os.path\n","from os import path\n","\n","if not path.exists(\"/content/current_metrics.txt\"):\n","    # download the current metrics\n","    !wget https://raw.githubusercontent.com/SaschaMet/melanoma-classification/master/evaluation/metrics.txt\n","    !mv /content/metrics.txt.1 /content/current_metrics.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHiEVTLQ0iM6"},"source":["print(\"current metrics\")\n","with open(\"/content/current_metrics.txt\") as json_file:\n","    current_metrics = json.load(json_file)\n","print(current_metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EilsGeLL0yg9"},"source":["print(\"new metrics\")\n","with open(\"/content/metrics.txt\") as json_file:\n","    metrics = json.load(json_file)\n","print(metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11tz4fyy00qw"},"source":["# check if the new model is better than the old one\n","is_better = True\n","\n","# if one metric is worse than a metric from the prev model, do not update the model\n","metrics_to_compare = ['f1score', 'precision', 'recall']\n","for metric in metrics_to_compare:\n","    if metrics[metric] < current_metrics[metric]:\n","        is_better = False\n","\n","print(\"New model is an improvement compared to the pre model:\", is_better)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PHY1vEG_02NL"},"source":["if not is_better:\n","    sys.exit(\"Stop execution because of inferior model\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8RLZAH___L0"},"source":["## save the model\n","model.save_weights(\"final_weights.hdf5\")\n","model.save(\"final_model.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5gSR1RiTilL"},"source":["# serialize model to json\n","json_model = model.to_json()\n","#save the model architecture to JSON file\n","with open('model.json', 'w') as json_file:\n","    json_file.write(json_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxciSoSuTtu4"},"source":["# create a new model for the predictions\n","#K.clear_session()\n","#with strategy.scope():\n","    #model = tf.keras.models.load_model(\"/content/final_model.h5\")\n","    #model.load_weights(\"final_weights.hdf5\")\n","    #model = compile_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j4w1KVxf95TK"},"source":["test_ds = get_test_dataset(ordered=True)\n","NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n","test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n","test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QNHsUzAPHWbL"},"source":["print('Computing predictions...')\n","test_images_ds = test_ds.map(lambda image, idnum: image)\n","probabilities = model.predict(test_images_ds, verbose=1, steps=math.ceil(len(test_ids) / BATCH_SIZE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1cjeGqXHSZq"},"source":["print('Generating submission.csv file...')\n","test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n","test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')\n","\n","pred_df = pd.DataFrame({'image_name': test_ids, 'target': np.concatenate(probabilities)})\n","pred_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tyhBT3fVs7Pr"},"source":["pred_df.to_csv(\"./submission.csv\", index=False)\n","!kaggle competitions submit -c siim-isic-melanoma-classification -f submission.csv -m \"Sub Xception\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9gR1ZSJFjVe"},"source":["sys.exit(\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K71NMxGqtolF"},"source":["## if the model is an improvement, push it!\n","!cd /content/melanoma-classification && git checkout -b xception\n","!cd /content/melanoma-classification && git checkout xception && git reset --hard origin/xception"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nE4tpmiT04wK"},"source":["!mkdir evaluation\n","\n","for f in glob.glob(\"/content/*auc.png\"):\n","    os.rename(f, \"auc.png\")\n","\n","for f in glob.glob(\"/content/*cm.png\"):\n","    os.rename(f, \"cm.png\")\n","\n","for f in glob.glob(\"/content/*history.png\"):\n","    os.rename(f, \"history.png\")\n","    \n","shutil.move(\"/content/model.json\", \"/content/evaluation/model.json\")\n","shutil.move(\"/content/final_model.h5\", \"/content/evaluation/model.hdf5\")\n","shutil.move(\"/content/history.png\", \"/content/evaluation/history.png\")\n","shutil.move(\"/content/cm.png\", \"/content/evaluation/cm.png\")\n","shutil.move(\"/content/auc.png\", \"/content/evaluation/auc.png\")\n","shutil.move(\"/content/metrics.txt\", \"/content/evaluation/metrics.txt\")\n","shutil.move(\"/content/current_metrics.txt\", \"/content/evaluation/current_metrics.txt\")\n","\n","!rm -rf /content/melanoma-classification/evaluation\n","!mv /content/evaluation /content/melanoma-classification/evaluation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ydNdr-Z4Nx1"},"source":["gh_auth = \"/content/drive/MyDrive/Colab Notebooks/_auth/gh_auth.txt\"\n","with open(gh_auth) as f:\n","    gh_auth = f.read()\n","\n","!cd /content/melanoma-classification && git config --global user.email \"sascha.metzger@outlook.com\"\n","!cd /content/melanoma-classification && git config --global user.name \"SaschaMet\"\n","\n","!cd /content/melanoma-classification && git remote remove origin\n","!cd /content/melanoma-classification && git remote add origin $gh_auth"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"970i1Gb4_qgX"},"source":["!cd /content/melanoma-classification && git fetch && git checkout xception && git status"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zc9BgQwr4j5F"},"source":["!cd /content/melanoma-classification && git checkout xception\n","!cd /content/melanoma-classification && git add .\n","!cd /content/melanoma-classification && git commit -m \"xception\"\n","!cd /content/melanoma-classification && git push -f"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jyOWwPSiVifd"},"source":["!cd /content/melanoma-classification && git status"],"execution_count":null,"outputs":[]}]}