{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":["import glob\n","import keras\n","import random\n","import os.path\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from pathlib import Path\n","from random import sample \n","from shutil import copyfile\n","from numpy.random import seed\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from keras.optimizers import Adam\n","from keras.models import Sequential, Model\n","from keras.preprocessing.image import load_img\n","from keras.applications.resnet50 import ResNet50\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.layers import Flatten, Dense, BatchNormalization, Lambda, Dropout"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(\"tf version\", tf.__version__)\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(\"Using default strategy for CPU and single GPU\")\n","strategy = tf.distribute.get_strategy()\n","\n","AUTO     = tf.data.experimental.AUTOTUNE\n","REPLICAS = strategy.num_replicas_in_sync\n","print(f'REPLICAS: {REPLICAS}')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Utility functions"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# ensure consistency across runs\n","seed(1)\n","tf.random.set_seed(1)\n","\n","is_kaggle = True\n","path_to_images = '../input/siim-isic-melanoma-classification/jpeg/train'\n","path_to_csv = \"../input/siim-isic-melanoma-classification/train.csv\"\n","\n","if not os.path.isfile(path_to_csv):\n","    is_kaggle = False\n","    path_to_images = 'input'\n","    path_to_csv = \"input/train.csv\""],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def get_data(path_to_csv):\n","    df = pd.read_csv(path_to_csv)\n","    return df\n","        \n","\n","\n","def check_for_missing_and_null(df):\n","    null_df = pd.DataFrame({\n","                            'percent_null': df.isnull().sum() * 100 / len(df),\n","                            'percent_zero': df.isin([0]).sum() * 100 / len(df)\n","                            })\n","    return null_df\n","\n","\n","def display_image(path):\n","    img = mpimg.imread(path)\n","    imgplot = plt.imshow(img)\n","    plt.show()\n","\n","def rgb2gray(rgb):\n","    # source: https://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python\n","    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n","\n","def standardize_image(imageData):\n","    # Find the mean and std dev intensity values of the image, and standerdize it\n","    mean_intensity = np.mean(imageData)\n","    std_intensity = np.std(imageData)\n","    new_img = imageData.copy()\n","    new_img = (new_img - mean_intensity)/std_intensity\n","    return new_img\n","\n","def image_distribution(path):\n","    ## helper function to print the image and the intensity distribution\n","    image = mpimg.imread(path)\n","    image = rgb2gray(image)  \n","\n","    f = plt.figure()\n","    f.set_figwidth(10)\n","    \n","    # standardize the image data\n","    image = standardize_image(image)\n","    \n","    s1 = f.add_subplot(1, 2, 1)\n","    s1.set_title('Image')\n","    plt.imshow(image, cmap='gray')\n","    \n","    s2 = f.add_subplot(1, 2, 2)\n","    s2.set_title('Intensity Distribution')\n","    plt.hist(image.ravel(), bins = 256)\n","    \n","    plt.show()\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df = get_data(path_to_csv)\n","df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["- The diagnosis feature is a simple diagnosis of the cancer.\n","- The benign_malignant feature is a feature that determines whether the tumor is benign or malignant (benign is harmless, malignant is harmful)\n","- The anatom_site_general_challenge tells us where the cancer is.\n","- The target is the target feature."]},{"metadata":{"trusted":true},"cell_type":"code","source":["for image_path in glob.glob(path_to_images + '/*.jpg')[:5]:\n","    display_image(image_path)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Data Exploration and Preprocessing\n","Source: https://towardsai.net/p/data-analysis/exploratory-data-analysis-in-python-ebdf643a33f6\n","\n","1. Identification of variables and data types\n","2. Analyzing the basic metrics\n","3. Non-Graphical Analysis\n","4. Graphical Analysis\n","5. Missing value treatment"]},{"metadata":{},"cell_type":"markdown","source":["### 1. Identification of variables and data types"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.dtypes"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We have two numerical variables (age_approx and target) and six categorial variables (image_name, patient_id, sex and anatom_site_general_challenge, diagnosis, benign_malignant)"]},{"metadata":{},"cell_type":"markdown","source":["### 2. Analyzing the basic metrics"]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(\"Number of rows in the dataset:\", df.shape[0])\n","print(\"Number of columns in the dataset:\", df.shape[1])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.describe()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The column age consits of 33.126 data points. The mean patient age is 49, the min age is 0 and the max age is 90. We will ignore the target columns in for now."]},{"metadata":{},"cell_type":"markdown","source":["### 3. Non-Graphical Analysis"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.patient_id.nunique()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.patient_id.value_counts()[:10]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Interestingly we only have 2.056 unique patients. From some patients we have have up to 115 images.\n","Maybe we have to consider this when we later check for Bias in our model. -> Why?"]},{"metadata":{},"cell_type":"markdown","source":["### 4. Graphical Analysis"]},{"metadata":{"trusted":true},"cell_type":"code","source":["custom_bins = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n","df.plot.hist(df.age_approx, bins=custom_bins)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["age_10_or_younger = df[df['age_approx'] < 11]\n","len(age_10_or_younger)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We have 19 images of patients age 10 or younger."]},{"metadata":{"trusted":true},"cell_type":"code","source":["ax = df.anatom_site_general_challenge.value_counts().plot(kind='bar')\n","ax.set(ylabel = 'Anatom Site')\n","\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We can see that skin lesions most often occur at the torso, followed by the lower extremity."]},{"metadata":{"trusted":true},"cell_type":"code","source":["ax = df.sex.value_counts().plot(kind='bar')\n","ax.set(ylabel = 'Anatom Site')\n","\n","print(\"Male patients\", len(df[df['sex']==\"male\"]))\n","print(\"Female patients\", len(df[df['sex']==\"female\"]))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["There are 1.099 more images of male patients than female patients in the dataset."]},{"metadata":{"trusted":true},"cell_type":"code","source":["male_df = df[df['sex']==\"male\"]\n","female_df = df[df['sex']==\"female\"]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["ax = male_df.anatom_site_general_challenge.value_counts().plot(kind='bar')\n","ax.set(ylabel = 'Anatom Site')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["ax = female_df.anatom_site_general_challenge.value_counts().plot(kind='bar')\n","ax.set(ylabel = 'Anatom Site')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["When looking at the body parts of the images and the genders we can see no differcence."]},{"metadata":{"trusted":true},"cell_type":"code","source":["for image_path in glob.glob(path_to_images + '/*.jpg')[:5]:\n","    image_distribution(image_path)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The intensity distribution of the images seem to follow normal distribution. "]},{"metadata":{},"cell_type":"markdown","source":["### 5. Missing value treatment"]},{"metadata":{"trusted":true},"cell_type":"code","source":["check_for_missing_and_null(df)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(\"Number of rows without data:\", df.anatom_site_general_challenge.isnull().sum())"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Because there are only 351 rows withou a value, I will remove these data points, because then we will have a clean df. "]},{"metadata":{"trusted":true},"cell_type":"code","source":["df = df.dropna() \n","check_for_missing_and_null(df)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.shape"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["After the data cleaning we have a dataset with eight colunmns and 32.531 rows. Now let's take a deeper look at the data."]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.head(1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["benign_df = df[df.benign_malignant == \"benign\"]\n","malignant_df = df[df.benign_malignant == \"malignant\"]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(\"Rows benign_df\", benign_df.shape[0])\n","print(\"Rows malignant_df\", malignant_df.shape[0])\n","print(\"%\", (malignant_df.shape[0] / benign_df.shape[0]) * 100)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We can see that arround 1.8 percent of all skin lesions are malignant."]},{"metadata":{"trusted":true},"cell_type":"code","source":["ax = df.diagnosis.value_counts().plot(kind='bar')\n","ax.set(ylabel = 'Diagnosis')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.diagnosis.value_counts()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We have seven types of diagnosed cancerous growths here:\n","\n","- Unkown: a possibly novel type of growth\n","- Nevus: (from Google) a usually non-cancerous disorder of pigment-producing skin cells commonly called birth marks or moles.\n","- Melanoma: Skin cancer's form (what we are working with)\n","- Seborrheic keratosis: Brown, waxy and patchy growths that are not related to skin cancer.\n","- Lentigo NOS: A type of skin cancer that starts from the outside of the skin and attacks by going inword.\n","- Lichenoid keratosis: It is a thin pigmented sort of plaque, if you will.\n","- Solar lentigo: Like lentigo but caused by UV rays from the sun (very common in Delhi)\n","- cafe-au-lait macule: French for \"coffee with milk\". These are brownish spots also called \"giraffe spots\".\n","- atypical melanocytic proliferation: Abnormal quantities of melanin appear on the skin.\n","\n","Unkown is with almost 80% the most ocurring value"]},{"metadata":{},"cell_type":"markdown","source":["## Prepare dataset"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.head(1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df[\"new image_path\"] = \"\"\n","for index, row in df.iterrows():\n","    df.at[index,'image_path'] = path_to_images + \"/\" + row['image_name'] + \".jpg\"\n","\n","del df['image_name']"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.head(1)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Get balanced dataset\n"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# 20 % in test set\n","# stratify makes sure that in your train set the specific class is balanced [if in the whole DF there are 40% of subjects with this class, then the train set will also have 40 %]\n","train_df, test_df = train_test_split(df, test_size = 0.2, stratify = df['target'])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(\"train\", train_df.shape)\n","print(\"test\", test_df.shape)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["ax = test_df.target.value_counts().plot(kind='bar')\n","ax.set(ylabel = 'Diagnosis')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["For better training we need to have a balanced test df"]},{"metadata":{"trusted":true},"cell_type":"code","source":["p_inds = test_df[test_df.target==1].index.tolist()\n","np_inds = test_df[test_df.target==0].index.tolist()\n","np_sample = sample(np_inds,len(p_inds))\n","test_df = test_df.loc[p_inds + np_sample]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["ax = test_df.target.value_counts().plot(kind='bar')\n","ax.set(ylabel = 'Diagnosis')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["test_df.shape"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["IMG_SIZE = (224, 224)\n","BATCH_SIZE = 64\n","\n","\n","def image_augmentation():\n","    \"\"\"Helper function to create ImageDataGenerator function\n","    Returns: image data generator function\n","    \"\"\"\n","    idg = ImageDataGenerator(rescale=1 / 255.0,\n","                            horizontal_flip=True,\n","                            vertical_flip=True,\n","                            height_shift_range=0.1,\n","                            width_shift_range=0.1,\n","                            rotation_range=25,\n","                            shear_range=0.1,\n","                            zoom_range=0.15)\n","    return idg\n","\n","\n","def make_train_gen(df):\n","    \"\"\"Generate batches of tensor image data with real-time data augmentation.\n","    The data will be looped over (in batches).\n","    Args:\n","        df ([dataframe]): [dataframe of the training data]\n","    Returns:\n","        [generator function]: Generator function for training data\n","    \"\"\"\n","    idg = image_augmentation()\n","    train_gen = idg.flow_from_dataframe(dataframe=df,\n","                                        directory=None,\n","                                        x_col='image_path',\n","                                        y_col='target',\n","                                        class_mode='raw',\n","                                        target_size=IMG_SIZE,\n","                                        batch_size=BATCH_SIZE\n","                                        )\n","    return train_gen\n","\n","\n","def make_test_gen(df):\n","    \"\"\"Generate batches of tensor image data with real-time data augmentation.\n","    The data will be looped over (in batches).\n","    Args:\n","        df ([dataframe]): [dataframe of the testing data]\n","    Returns:\n","        [generator function]: Generator function for testing data\n","    \"\"\"\n","    test_idg = ImageDataGenerator(rescale=1. / 255.0)\n","    test_gen = test_idg.flow_from_dataframe(dataframe=df,\n","                                            directory=None,\n","                                            x_col='image_path',\n","                                            y_col='target',\n","                                            class_mode='raw',\n","                                            shuffle=False,\n","                                            target_size=IMG_SIZE,\n","                                            batch_size=BATCH_SIZE)\n","    return test_gen\n","\n","\n","def create_train_data(train_df):\n","    train_gen = make_train_gen(train_df)\n","    return train_gen\n","\n","\n","def create_test_data(test_df):\n","    train_gen = make_test_gen(test_df)\n","    return train_gen"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["test_gen = create_test_data(test_df)\n","train_gen = create_train_data(train_df)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Model"]},{"metadata":{},"cell_type":"markdown","source":["We will use ResNet, because it has the best accuracy and a good training time. If you want to read more about it, here is a great article: https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96\n","\n","For a guid to Transfer Learning with the ResNet50 visit: https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b"]},{"metadata":{"trusted":true},"cell_type":"code","source":["input_shape = (224, 224, 3)"],"execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":["# The option include_top=False allows feature extraction by removing the last dense layers. This let us control the output and input of the model.\n","res_model = ResNet50(weights='imagenet', include_top=False, input_tensor=tf.keras.Input(shape=input_shape))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(\"Number of layers:\", len(res_model.layers))\n","\n","for layer in res_model.layers[:143]:\n","    layer.trainable = False\n","\n","for layer in res_model.layers[138:]:\n","    print(layer.name, '-', layer.trainable)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# New Sequentail Model\n","model = Sequential()\n","\n","# Add the convolutional part of the VGG16 model \n","model.add(res_model)\n","\n","# Flatten the output of the res_model model because it is from a convolutional layer.\n","model.add(Flatten())\n","## ?????\n","model.add(BatchNormalization())\n","# Add a dense (aka. fully-connected) layer. This is for combining features that the res_model model has recognized in the image.\n","model.add(Dense(256, activation='relu'))\n","# Add a dropout-layer which may prevent overfitting and improve generalization ability to unseen data e.g. the test-set.\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","## ?????\n","model.add(BatchNormalization())\n","# Add a dense (aka. fully-connected) layer. This is for combining features that the res_model model has recognized in the image.\n","model.add(Dense(128, activation='relu'))\n","# Add a dropout-layer which may prevent overfitting and improve generalization ability to unseen data e.g. the test-set.\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","## ?????\n","model.add(BatchNormalization())\n","# Add a dense (aka. fully-connected) layer. This is for combining features that the res_model model has recognized in the image.\n","model.add(Dense(64, activation='relu'))\n","# Add a dropout-layer which may prevent overfitting and improve generalization ability to unseen data e.g. the test-set.\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(1, activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["model.summary()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["EPOCHS = 30\n","LEARNING_RATE = 1e-4"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["## Set our optimizer, loss function, and learning rate\n","optimizer = Adam(lr=LEARNING_RATE)\n","loss = 'binary_crossentropy'\n","metrics=['binary_crossentropy', 'accuracy']\n","\n","# Compile the model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def save_history(history):\n","    \"\"\"Helper function to save a png image of the loss and accuracy\n","    Args:\n","        history ([tf history]): The history object of a tf model\n","    \"\"\"\n","    f = plt.figure()\n","    f.set_figwidth(15)\n","\n","    f.add_subplot(1, 2, 1)\n","    plt.plot(history.history['val_loss'], label='val loss')\n","    plt.plot(history.history['loss'], label='train loss')\n","    plt.legend()\n","    plt.title(\"Modell Loss\")\n","\n","    f.add_subplot(1, 2, 2)\n","    plt.plot(history.history['val_accuracy'], label='val accuracy')\n","    plt.plot(history.history['accuracy'], label='train accuracy')\n","    plt.legend()\n","    plt.title(\"Modell Accuracy\")\n","\n","    plt.savefig(DIRECTORY_ROOT + '/model/history.png')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["weight_path = \"model.hdf5\"\n","checkpoint = ModelCheckpoint(weight_path,\n","                            monitor='val_loss',\n","                            verbose=1,\n","                            save_best_only=True,\n","                            mode='auto',\n","                            save_weights_only=True)\n","\n","early = EarlyStopping(monitor='val_loss',\n","                    mode='auto',\n","                    patience=10)\n","\n","callbacks_list = [checkpoint, early]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["testX, testY = test_gen.next() "],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["history = model.fit(train_gen, validation_data=(testX, testY), epochs=EPOCHS, callbacks=callbacks_list, verbose=1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["save_history(history)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# save model architecture to a .json:\n","model_json = model.to_json()\n","with open(DIRECTORY_ROOT + \"my_model.json\", \"w\") as json_file:\n","    json_file.write(model_json)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":[],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}